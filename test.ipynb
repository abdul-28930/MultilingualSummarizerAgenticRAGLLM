{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install ipywidgets\n",
    "%pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n",
    "%pip install --upgrade ipywidgets\n",
    "%pip install notebook\n",
    "%pip install jupyterlab\n",
    "%pip install widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"humbleakh/whisper-small-arabic\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "# Load the processor from the base model\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"humbleakh/whisper-small-arabic\")\n",
    "\n",
    "# Configure the processor for Arabic\n",
    "processor.tokenizer.set_prefix_tokens(language=\"arabic\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, pipeline\n",
    "import gradio as gr\n",
    "import torch\n",
    "\n",
    "# Create pipeline with your fine-tuned model and proper configuration\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=\"humbleakh/whisper-small-arabic\",\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    chunk_length_s=30,  # Process in 30-second chunks\n",
    "    return_timestamps=True  # Enable timestamp tokens\n",
    ")\n",
    "\n",
    "def transcribe(audio):\n",
    "    try:\n",
    "        result = pipe(\n",
    "            audio,\n",
    "            batch_size=1,\n",
    "            generate_kwargs={\n",
    "                \"language\": \"arabic\",\n",
    "                \"task\": \"transcribe\",\n",
    "                \"return_timestamps\": True\n",
    "            }\n",
    "        )\n",
    "        # Extract just the text from the result\n",
    "        return result[\"text\"] if isinstance(result, dict) else result\n",
    "    except Exception as e:\n",
    "        return f\"Error during transcription: {str(e)}\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe, \n",
    "    inputs=gr.Audio(\n",
    "        type=\"filepath\",\n",
    "        label=\"Upload Audio File (supports long files)\",\n",
    "        sources=[\"upload\"]\n",
    "    ),\n",
    "    outputs=gr.Textbox(\n",
    "        label=\"Transcription\",\n",
    "        show_copy_button=True\n",
    "    ),\n",
    "    title=\"Whisper Small Arabic\",\n",
    "    description=\"Upload an Arabic audio file for transcription. Supports long audio files (WER: 44.17%)\",\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
